{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sagemaker\n",
    "\n",
    "## Contents\n",
    "\n",
    " 1. [Introduction](#Introduction)\n",
    "    1. [The High Level Library](#The-High-Level-Library)\n",
    " 2. [Goal for this tutorial](#Goal-For-This-Tutorial)\n",
    "    1. [Imports](#Imports)\n",
    "    2. [Training the Model](#Training-the-Model)\n",
    "    3. [Deploying the Model](#Deploying-the-Model)\n",
    "    4. [Summary](#Summary)\n",
    " 3. [Defining the Python Script](#Defining-the-Python-Script)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "\n",
    "Sagemaker allows us to do all of our analysis through a Jupyter Notebook interface\n",
    "and all that is required is the code and an AWS account (Free Tier is included).\n",
    "\n",
    "### The High Level Library\n",
    "\n",
    "When you are a first time user of Sagemaker, the experience needs to be\n",
    "as seamless as possible, this is why amazon has implemented a high level\n",
    "python library that abstracts most of the complexities involved in training\n",
    "and deploying machine learning models.\n",
    "\n",
    "## Goal For This Tutorial\n",
    "\n",
    "The Goal is to train a  Convolutional Neural Network on CIFAR-10 and deploy it in the cloud.\n",
    "To use the Sagemakers API we need to have  a training script. This script can be written\n",
    "in any of the major Deep learning frameworks (Tensorflow, Pytorch, Chainer and MXNet).\n",
    "\n",
    "For this example we will be using MXNet due to its simplicity.\n",
    "\n",
    "Let's start with the syntax required, we can start with the library imports that are required:\n",
    "\n",
    "### Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet as MXNetEstimator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The last line of the imports brings in the MXNet specific class of Sagemaker's Estimators.\n",
    "The Estimators encapsule everything required to train a model, these consist of:\n",
    "\n",
    " - Methods and functions wrapping your training code\n",
    " - a docker image used as the environment for traning your model\n",
    "\n",
    "Using the MXNetEstimator instead of a generic Estimator class means we do not need to explicitly\n",
    "provide a Docker image as a default image. It is also possible to setup a custom image. In this case\n",
    "we will be using the default image and move onto loading the data.\n",
    "\n",
    "### Loading the Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mx.test_utils.get_cifar10()\n",
    "sagemaker_session = sagemaker.session()\n",
    "inputs = sagemaker_session.upload_data(path='data/cifar',key_prefix='data/cifar10')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "in this code section the Sagemaker Session is used to upload the dataset to an s3 bucket\n",
    "which will be accessed by our Estimator.\n",
    "\n",
    "### Training the Model\n",
    "\n",
    "We can now start training the model. We do this using the MXNetEstimator and use the provided\n",
    "fit method."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "estimator = MXNetEstimator(entry_point='train.py',role=sagemaker.get_execution_role(),\n",
    "                           train_instance_count=1,train_instance_type='ml.p3.2xlarge',\n",
    "                           hyperparameters={'batch_size':1024,'epochs':30})\n",
    "estimator.fit(inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code segment is doing the following:\n",
    "\n",
    "The MXNetEstimator requires an entry point which is our training script. This python file must take\n",
    "a specific format that will be described later. We will also need to specify our AWS Role. Amongst other\n",
    "things the AWS Role will determine what kind of EC2 instances we can access. In this snippet we requested one\n",
    "`ml.p3.2xlarge` instance which contains a GPU for accelerated computing.\n",
    "\n",
    "The final thing we do is specify the hyperparameters in a dictionary that will be used by the training script in the\n",
    "python file.\n",
    "\n",
    "Calling the fit method will launch the requested EC2 instance as a training environment, setup the docker\n",
    "image on it and start the training loop. Once this is done, we can deploy the model with the deploy method.\n",
    "\n",
    "### Deploying the Model\n",
    "\n",
    "When we call the deploy method, Sagemaker uploads the trained model to the S3 bucket and creates the predictive environment.\n",
    "It also returns a Predictor (This is the interface we will use to predict new inputs)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type= 'ml.m4.xlarge')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see from the code it is possible to deploy the model on a different type of instance that the estimator,\n",
    "This can assist as we may not require as much processing power to apply a model versus training a model.\n",
    "\n",
    "We can now do some prediction with the deployed model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, img in enumerate(image_data):\n",
    "    response = predictor.predict(img)\n",
    "    print('image {}:class: {}'.format(i,int(response)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once the deployed model is no longer required we can close down the deployed the model with the following:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "estimator.delete_endpoint()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Summary\n",
    "\n",
    "In the syntax we have seen how to fit the MXNet Estimator, deploy it and then use the predictor on new inputs.\n",
    "All of these methods rely on the python script. Which we will look at now.\n",
    "\n",
    "## Defining the Python Script\n",
    "\n",
    "The training loop and prediction code will be nested inside SageMakers Library as such it should follow the follow a certain format.\n",
    "The code will require four sections to be present:\n",
    "\n",
    " - Train\n",
    "    - A function to implement the training loop\n",
    " - Save\n",
    "    - A function to save the model\n",
    " - model_fn\n",
    "    - A function to load the model\n",
    " - transfom_fn\n",
    "    - A function to predict the inputs\n",
    "\n",
    "Only the first two functions will be used during the training phase. We can look at what an example of the code should look like here:\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(channel_input_dirs, hyperparameters):\n",
    "\n",
    "    # Retrieve the hyperparameters\n",
    "    batch_size = hyperparameters.get('batch_size', 55)\n",
    "    epochs = hyperparameters.get('epochs', 100)\n",
    "\n",
    "    # Prepare the data\n",
    "    data_dir = channel_input_dirs['training']\n",
    "    train_data = get_data(data_dir, batch_size, train=True)\n",
    "\n",
    "    # Create the model\n",
    "    net = models.get_model('resnet34_v2', ctx=mx.gpu(), pretrained=False, classes=10)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "    # Your training loop goes here.\n",
    "    return net\n",
    "\n",
    "def save(net, model_dir):\n",
    "    net.save_params('%s/model.params' % model_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The content of the train function is not that much different from a default train function of MXNet, you set the hyperparameters, get the data, define the model and start running the model.\n",
    "\n",
    "To make it work Sagemaker provides you with the information you need, the location of the data and the hyperparameters dictionary. Importantly the train function should return the trained\n",
    "network.\n",
    "\n",
    "The Save Function is even simplier, You receive as input the trained model as well  as the directory to save its parameters.\n",
    "\n",
    "The last two functions in the script is used to deploy the model, Lets have a look at what should be contained in them:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def model_fn(model_dir):\n",
    "    net = models.get_model('resnet34_v2', ctx=mx.cpu(), pretrained=False, classes=10)\n",
    "    net.load_params('%s/model.params' % model_dir, ctx=mx.cpu())\n",
    "    return net\n",
    "\n",
    "\n",
    "def transform_fn(net, data, input_content_type, output_content_type):\n",
    "    inputs = mx.nd.array(json.loads(data))\n",
    "    outputs = net(inputs)\n",
    "    predictions = mx.nd.argmax(outputs, axis=1)\n",
    "    response = json.dumps(predictions.asnumpy().tolist()[0])\n",
    "    return response, output_content_type"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model_fn function will simply load the model while transform_fn will process the new predictions. Note that the inputs variable\n",
    "in transform_fn is originally in a json format and we need to convert it to an MX.nd.Array. The reason for this is the prediction\n",
    "requests in Sagemaker are communicated through HTTPS. With this being the case we will need to translate the network's outputs\n",
    "back to JSON so it can be properly used by the downstream code.\n",
    "\n",
    "From these examples we can see that the format the code needs to follow is neither too restrictive nor complicated to implement"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}