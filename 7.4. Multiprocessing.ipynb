{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    " 1. [Introduction](#Introduction)\n",
    "     1. [Multithreading vs Multiprocessing](#Multithreading-vs-Multiprocessing)\n",
    " 2. [Multiprocessing vs Multithreading Source](#Multiprocessing-vs-Multithreading-Source)\n",
    " 3. [Python Concurrent Futures](#Python-Concurrent-Futures)\n",
    "    1. [Executor Class](#Executor-Class)\n",
    "    2. [Thread Pool Executor](#Thread-Pool-Executor)\n",
    "    3. [Process Pool Operator](#Process-Pool-Operator)\n",
    "    4. [Example of using concurrent futures](#Example-of-using-concurrent-futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Multiprocessing is one of the methods that enables us to speed up processing time by alieviating the amount of processing that\n",
    "is performed on a single thread or processor\n",
    "\n",
    "this can be done using various different methods and we will explore these initially"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Multithreading vs Multiprocessing\n",
    "\n",
    "This section will cover a few misconceptions around the two topics with the processing that is performed in Python.\n",
    "\n",
    "The first thing to understand is the two modules that are used in Python: **Threading** and **Multiprocessing**, the big difference\n",
    "between these two is the threading module uses threads which work in the same memory space while the multiprocessing module uses processes\n",
    "which use difference memory spaces.\n",
    "\n",
    "There are more differences between multithreading and multiprocessing which we need to understand to decide on the best deployment.\n",
    "\n",
    "Using an experiement with the following code:\n",
    "\n",
    "```\n",
    "def cpu_heavy(x):\n",
    "    print('I am', x)\n",
    "    count = 0\n",
    "    for i in range(10**8):\n",
    "        count += i\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "def multithreading(func, args, workers):\n",
    "    with ThreadPoolExecutor(workers) as ex:\n",
    "        res = ex.map(func, args)\n",
    "    return list(res)\n",
    "def multiprocessing(func, args, workers):\n",
    "    with ProcessPoolExecutor(workers) as ex:\n",
    "        res = ex.map(func, args)\n",
    "    return list(res)\n",
    "\n",
    "visualize_runtimes(multithreading(cpu_heavy, range(4), 4))\n",
    "visualize_runtimes(multiprocessing(cpu_heavy, range(4), 4))\n",
    "```\n",
    "A graphical representation is created showing that the Multithreading took 20 seconds while Multiprocessing only took 5 seconds,\n",
    "But this seems strange as a **common misconception** is that these perform in the same way.\n",
    "\n",
    "(Source: https://github.com/baatout/multithreading-vs-multiprocessing/blob/master/live_comparison.py)\n",
    "\n",
    "The biggest difference between the two of these processes is that Threadpool does not run in parellel, this can be seen by\n",
    "measuring the start time for each successive iteration. With the Threadpool you will see that although all of the threads are run they\n",
    "are run at different moments concurrently.\n",
    "\n",
    "Another big misconception is the use of multithreading to make code faster, this is not the case as in python it could possibly make\n",
    "the code slower. This is because the processing is still done in a serial manner but also needs time to switch between the threads.\n",
    "\n",
    "Even though this is not sounding good for multithreading at the moment, this discussion has been very skewed towards processing\n",
    "and not all the other use cases. Multithreading is actually very useful for setting up IO processes to speed up the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Multiprocessing vs Multithreading Source\n",
    "\n",
    "https://medium.com/contentsquare-engineering-blog/multithreading-vs-multiprocessing-in-python-ece023ad55a"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Python Concurrent Futures"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Concurrent futures module provides high-level interface for asynchronous executing callables. The asynchronous\n",
    "execution can be done either through threads using **ThreadPoolExecutor** or processes using **ProcessPoolExecutor**.\n",
    "Both of these executions implement the **Executor** class."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Executor Class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is a class that provides methods that can be used to execute calls asynchronously, it should not be used directly\n",
    "but rather through its subclasses.\n",
    "\n",
    "### Thread Pool Executor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This class is an executor subclass that uses a pool of threads to execute calls asynchronously. One of the areas to watch out\n",
    "for is possible deadlocks while a future waits for the results of another future. For Example:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def wait_on_b():\n",
    "    time.sleep(5)\n",
    "    print(b.result)\n",
    "    return 5\n",
    "def wait_on_a():\n",
    "    time.sleep(5)\n",
    "    print(a.result())\n",
    "    return 6\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=2)\n",
    "a = executor.submit(wait_on_b)\n",
    "b = executor.submit(wait_on_a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This will never finish as `a is waiting on b` and `b is waiting on a`.\n",
    "\n",
    "Another way that a Deadlock can occur is shown below:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Future at 0x1220c81c0 state=running>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Future.result of <Future at 0x1224f8820 state=pending>>\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def wait_on_future():\n",
    "    f = executor.submit(pow,5,2)\n",
    "    print(f.result)\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=1)\n",
    "executor.submit(wait_on_future)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This will never complete as the executor only has one thread but it is trying to do multiple calls at the same time.\n",
    "\n",
    "Now that we have seen causes of deadlocks lets start to look at how we can use the ThreadPoolExecutor to do a proper run:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'http://europe.wsj.com/' generated an exception: HTTP Error 403: Forbidden\n",
      "'http://www.foxnews.com/' page is 288814 bytes\n",
      "'http://some-made-up-domain.com/' page is 64668 bytes\n",
      "'http://www.cnn.com/' page is 1138977 bytes\n",
      "'http://www.bbc.co.uk/' page is 311362 bytes\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import urllib.request\n",
    "\n",
    "URLS = ['http://www.foxnews.com/',\n",
    "        'http://www.cnn.com/',\n",
    "        'http://europe.wsj.com/',\n",
    "        'http://www.bbc.co.uk/',\n",
    "        'http://some-made-up-domain.com/']\n",
    "\n",
    "def load_url(url, timeout):\n",
    "    with urllib.request.urlopen(url, timeout=timeout) as conn:\n",
    "        return conn.read()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}\n",
    "    for future in concurrent.futures.as_completed(future_to_url):\n",
    "        url = future_to_url[future]\n",
    "        try:\n",
    "            data = future.result()\n",
    "        except Exception as exc:\n",
    "            print('%r generated an exception: %s' % (url, exc))\n",
    "        else:\n",
    "            print('%r page is %d bytes' % (url, len(data)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This syntax submits a URL at a time to a set of futures and then outputs the results as soon as the futures\n",
    "has completed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process Pool Operator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is a subclass of executor that uses a pool of processes to execute calls asynchronously. This module\n",
    "uses the multiprocessing module."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example of using concurrent futures"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "16\n",
      "9\n",
      "25\n",
      "36\n",
      "9\n",
      "49\n",
      "25\n",
      "64\n",
      "100\n",
      "1\n",
      "16\n",
      "9\n",
      "25\n",
      "36\n",
      "9\n",
      "49\n",
      "25\n",
      "64\n",
      "100\n",
      "1\n",
      "16\n",
      "9\n",
      "25\n",
      "36\n",
      "9\n",
      "49\n",
      "25\n",
      "64\n",
      "100\n",
      "1\n",
      "16\n",
      "9\n",
      "25\n",
      "36\n",
      "9\n",
      "49\n",
      "25\n",
      "64\n",
      "100\n",
      "1\n",
      "16\n",
      "9\n",
      "25\n",
      "36\n",
      "9\n",
      "49\n",
      "25\n",
      "64\n",
      "100\n",
      "1\n",
      "16\n",
      "9\n",
      "25\n",
      "36\n",
      "9\n",
      "49\n",
      "25\n",
      "64\n",
      "100\n",
      "1\n",
      "16\n",
      "9\n",
      "25\n",
      "36\n",
      "9\n",
      "49\n",
      "25\n",
      "64\n",
      "100\n",
      "1\n",
      "16\n",
      "9\n",
      "25\n",
      "36\n",
      "9\n",
      "49\n",
      "25\n",
      "64\n",
      "100\n",
      "26 s ± 1.49 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "\n",
    "def power_calc(x):\n",
    "    time.sleep(x/2)\n",
    "    return pow(x,2)\n",
    "\n",
    "values = [1,4,3,5,6,3,7,5,8,10]\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(power_calc,value) for value in values]\n",
    "    results = [result.result() for result in futures]\n",
    "\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the syntax above we can summarise the following timings that it takes to complete with different number of Threads:\n",
    "\n",
    "| Threads | Time |\n",
    "| --- | --- |\n",
    "| No Threads| 26 Seconds |\n",
    "| 2 | 13.5 seconds |\n",
    "| 5 | 7.51 seconds |\n",
    "| 7 | 6.41 seconds |\n",
    "| 10 | 5.01 seconds |\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## DASK\n",
    "\n",
    "Dask allows for multi core execution on larger-than memory datasets. We can think of Dask as a Higher level\n",
    "and lower level:\n",
    "\n",
    " - **High Level**: Dask Provides High-level Array and DataFrame collections that mimic Numpy and Pandas but can\n",
    " operate in parrallel in data that does not fit into memory. These are alternatives to the Numpy and Pandas Datasets.\n",
    " - **Low Level**: The low level includes schedulers. This provides us with dynamic task schedulers. This is the Dask equivalent\n",
    " to threading and multiprocessing.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}